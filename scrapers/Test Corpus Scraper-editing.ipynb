{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import nltk\n",
    "#nltk.dowload('words')\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function that converts a list to a string\n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    \n",
    "    # return string   \n",
    "    return (str1.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_menusII(url):\n",
    "    myfile = requests.get(url)\n",
    "    soup = BeautifulSoup(myfile.content)\n",
    "    \n",
    "    headers = soup.findAll(\"div\", {\"class\": \"menu-item-header__3xwnFL-n\"})\n",
    "    descriptions = soup.findAll(\"p\", {\"class\": \"menu-description__2HXkC4oE\"})\n",
    "    menu = headers + descriptions\n",
    "    \n",
    "    for w in range(0, len(menu)):   \n",
    "        menu[w] = str(menu[w])                     #converting the objects to strings\n",
    "        menu[w] = re.sub('<[^>]+>', '', menu[w])   #eliminaiting the scripts in between <>\n",
    "        \n",
    "    menu = [' '.join(w for w in menu)] \n",
    "    \n",
    "    menu = listToString(menu)\n",
    "    menu = menu.lower() #lowercasing every word\n",
    "    \n",
    "    menu = re.sub('[^a-zA-ZÀ-ÿ.\\s]', '', menu) #removing all the numbers and special characters\n",
    "    menu = menu.replace(\".\", \"\")\n",
    "\n",
    "    return menu\n",
    "\n",
    "test1 = get_menusII(\"https://www.opentable.com/r/tortino-washington?corrid=6e65cfb5-6e6c-49cc-bb40-850d84d83f38&p=2&sd=2020-06-18+19%3A00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooking_corpus_creator(url):\n",
    "    myfile = requests.get(url)\n",
    "    soup = BeautifulSoup(myfile.content)\n",
    "    \n",
    "    cooking_words = soup.findAll(\"div\", {\"class\": \"wordlist-item\"})\n",
    "    \n",
    "    for w in range(0, len(cooking_words)):   \n",
    "        cooking_words[w] = str(cooking_words[w])                     #converting the objects to strings\n",
    "        cooking_words[w] = re.sub('<[^>]+>', '', cooking_words[w])\n",
    "    \n",
    "    return cooking_words\n",
    "\n",
    "cooking_corpus_creator(\"https://www.enchantedlearning.com/wordlist/cooking.shtml\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_words = cooking_corpus_creator(\"https://www.enchantedlearning.com/wordlist/food.shtml\") \n",
    "food_verbs = cooking_corpus_creator(\"https://www.enchantedlearning.com/wordlist/cooking.shtml\") \n",
    "cooking_vocabulary = food_words + food_verbs\n",
    "cooking_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer(\"ed$|'s$\")\n",
    "stemmer1 = RegexpStemmer(\"d$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english(text):\n",
    "    \n",
    "    text = treebank_tokenizer.tokenize(text)\n",
    "    lemmatized_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    lemmatized_text = [w for w in lemmatized_text if w not in cooking_vocabulary]\n",
    "    \n",
    "    lemmatized_stemmed_text = []\n",
    "\n",
    "    for w in lemmatized_text:\n",
    "        w = stemmer.stem(w)\n",
    "        w = stemmer1.stem(w)\n",
    "        lemmatized_stemmed_text.append(w)\n",
    "        \n",
    "    tokenized_Italian_text = [w for w in lemmatized_stemmed_text if w not in words.words()]\n",
    "    Italian_text = ' '.join(tokenized_Italian_text)\n",
    "    \n",
    "    Italian_text = re.sub('[^a-zA-ZÀ-ÿ.\\s]', '', Italian_text) #removing all the numbers and special characters\n",
    "    \n",
    "    return Italian_text\n",
    "\n",
    "remove_english(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"mushroom\" in words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english(text):\n",
    "    \n",
    "    text = treebank_tokenizer.tokenize(text)\n",
    "    lemmatized_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    lemmatized_text = [w for w in lemmatized_text if w not in cooking_vocabulary]\n",
    "\n",
    "    \n",
    "    lemmatized_stemmed_text = []\n",
    "\n",
    "    for w in lemmatized_text:\n",
    "        w = stemmer.stem(w)\n",
    "        w = stemmer1.stem(w)\n",
    "        lemmatized_stemmed_text.append(w)\n",
    "        \n",
    "    tokenized_Italian_text = [w for w in lemmatized_stemmed_text if w not in words.words()]\n",
    "    tokenized_Italian_text = [w for w in tokenized_Italian_text if w not in cooking_vocabulary]\n",
    "    Italian_text = ' '.join(tokenized_Italian_text)\n",
    "    \n",
    "    Italian_text = re.sub('[^a-zA-ZÀ-ÿ.\\s]', '', Italian_text) #removing all the numbers and special characters\n",
    "    \n",
    "    return Italian_text\n",
    "\n",
    "remove_english(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
