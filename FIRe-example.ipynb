{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of FIRe scoring system on 10 menus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import simplejson as json\n",
    "from analysis.simple_spell import *\n",
    "from scrapers.TestCorpusScraper_editing import *\n",
    "from analysis.scoring import *\n",
    "from analysis.Indexes import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads the corpus we created to assess authencity of restaurants' menu. We display some of the main features of this corpus as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the background corpus\n",
    "with open('data/Background Corpora.json', 'r') as j:\n",
    "        Background_Corpora_Json = json.load(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spaghetti', 'guanciale', 'tuorli', 'uova', 'medie', 'pecorino', 'romano', 'pepe', 'nero', 'preparare', 'carbonara', 'cominciate', 'mettendo', 'fuoco', 'pentola', 'lacqua', 'salata', 'cuocere', 'pasta', 'frattempo', 'eliminate', 'cotenna', 'tagliatelo', 'prima', 'fette', 'poi', 'striscioline', 'spesse', 'circa', 'cm']\n"
     ]
    }
   ],
   "source": [
    "all_tokens = get_alltokens(Background_Corpora_Json)\n",
    "print(all_tokens[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['spaghetti', 'guanciale', 'tuorli'], ['guanciale', 'tuorli', 'di'], ['tuorli', 'di', 'uova'], ['di', 'uova', 'medie'], ['uova', 'medie', 'pecorino'], ['medie', 'pecorino', 'romano'], ['pecorino', 'romano', 'pepe'], ['romano', 'pepe', 'nero'], ['pepe', 'nero', 'per'], ['nero', 'per', 'preparare'], ['per', 'preparare', 'gli'], ['preparare', 'gli', 'spaghetti'], ['gli', 'spaghetti', 'alla'], ['spaghetti', 'alla', 'carbonara'], ['alla', 'carbonara', 'cominciate'], ['carbonara', 'cominciate', 'mettendo'], ['cominciate', 'mettendo', 'sul'], ['mettendo', 'sul', 'fuoco'], ['sul', 'fuoco', 'una'], ['fuoco', 'una', 'pentola']]\n"
     ]
    }
   ],
   "source": [
    "all_ngrams = ngrams_it(Background_Corpora_Json)\n",
    "print(all_ngrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-e6279370a9e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfr_grams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq_grams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_ngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_grams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Matteo/Desktop/NLP/project/FIRe-Fake-Italian-Restaurants-evaluator/analysis/Indexes.py\u001b[0m in \u001b[0;36mfreq_grams\u001b[0;34m(grams)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mfreq_grams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mgram\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq_grams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mfreq_grams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "fr_grams = freq_grams(all_ngrams)\n",
    "fr_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spaghetti', 'guanciale', 'tuorli', 'uova', 'medie']\n",
      "[41, 25, 22, 71, 16]\n"
     ]
    }
   ],
   "source": [
    "words_freq = tf(Background_Corpora_Json)\n",
    "words_freq[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e68f04c53022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBackground_Corpora_Json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc_terms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "doc_terms = tf_doc(Background_Corpora_Json)\n",
    "doc_terms[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dab45d6a738a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterm_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBackground_Corpora_Json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mterm_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Matteo/Desktop/NLP/project/FIRe-Fake-Italian-Restaurants-evaluator/analysis/Indexes.py\u001b[0m in \u001b[0;36minv_index\u001b[0;34m(corpus, all_tokens)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokens_stopw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Matteo/Desktop/NLP/project/FIRe-Fake-Italian-Restaurants-evaluator/analysis/Indexes.py\u001b[0m in \u001b[0;36mget_tokens_stopw\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_tokens_stopw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpunkt_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msentences_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreebank_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunkt_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_words\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Matteo/Desktop/NLP/project/FIRe-Fake-Italian-Restaurants-evaluator/analysis/Indexes.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_tokens_stopw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpunkt_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msentences_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreebank_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunkt_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_words\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Matteo/opt/anaconda3/lib/python3.7/site-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENDING_QUOTES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Matteo/opt/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "term_docs = inv_index(Background_Corpora_Json, all_tokens)\n",
    "term_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_dic = term_grams(all_tokens, all_ngrams)\n",
    "grams_dic[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples from our Test corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read and analyze the 10 menus from our scraped corpus and provide some insights as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the background corpus\n",
    "with open('data/Test Corpus.json', 'r') as j:\n",
    "        Test_Corpus_Json = json.load(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d96ba293099e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_tokens_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokens_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest_Corpus_Json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_tokens_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "all_tokens_test = get_tokens_test(Test_Corpus_Json)\n",
    "all_tokens_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-835c3c07bb81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmenus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_menu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tokens_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmenus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "menus = set_menu(all_tokens_test)\n",
    "menus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for typos in the menus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}\n",
    "for key, value in menus.items():\n",
    "    result, errs = checker(words_freq.keys(), value)\n",
    "    final_results[key] = result, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(result):\n",
    "    if result <= 5:\n",
    "        scores = 5\n",
    "        img = mpimg.imread('images/nonna-open.jpg')\n",
    "    elif result >= 6 and result <= 10:\n",
    "        scores = 4\n",
    "        img = mpimg.imread('images/Red-Sauce-Raos.jpg')\n",
    "    elif result >= 11 and result <= 15:\n",
    "        scores = 3\n",
    "        img = mpimg.imread('images/rosie-s-italian-grille.jpg')\n",
    "    elif result >= 16 and result <= 20:\n",
    "        scores = 2\n",
    "        img = mpimg.imread('images/olive_garden.jpg')\n",
    "    else:\n",
    "        scores = 1\n",
    "        img = mpimg.imread('images/pizza_deep.jpg')\n",
    "\n",
    "    return scores, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign our scores to each menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_scoring = {}\n",
    "for key, value in final_results.items():\n",
    "    score, img = scoring(value[0])\n",
    "    dic_scoring[key] = value, score, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errors = []\n",
    "for key, value in dic_scoring.items():\n",
    "    df = {'Restaurant': key, 'Errors': value[0][1], '# Errors': value[0][0], 'Score': value[1]}\n",
    "    df_errors.append(df)\n",
    "df_errors = pd.DataFrame(df_errors, columns=['Restaurant', 'Errors','# Errors', 'Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's how these restaurants performed and what mistakes our program detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Errors</th>\n",
       "      <th># Errors</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Il Canale - Washington, DC</td>\n",
       "      <td>[georgetown, rolle, tunnarella, ciliegina, imb...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La Storia - Chicago, IL</td>\n",
       "      <td>[neri, orecchitte, spalla, agnelo, malloreddus...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Osteria la Spiga - Seattle, WA</td>\n",
       "      <td>[ragu, piadina, cestino, stuzzichini, ida, gno...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Ricchi - Washington, DC</td>\n",
       "      <td>[romagnola, salsiccie, trota, buratta, paillar...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Via dei Tribunali - Seattle, WA</td>\n",
       "      <td>[cappuccino, caffe, espresso, puttanesca, dant...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Il Terrazzo Carmine - Seattle, WA</td>\n",
       "      <td>[affogati, ortolano, spaghettini, asparaci, an...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Otello - Washington, DC</td>\n",
       "      <td>[cappuccino, episelli, trota, espresso, mirell...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valentinos - Nashville, TN</td>\n",
       "      <td>[arugula, parmesan, manhattan, scottish, espre...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ristorante Piccolo - Washington, DC</td>\n",
       "      <td>[arugula, cioppino, altopiano, parigina, scarp...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portofino - Arlington, VA</td>\n",
       "      <td>[vinci, omaggi, veronese, picatta, cioppino, a...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Restaurant  \\\n",
       "5           Il Canale - Washington, DC   \n",
       "1              La Storia - Chicago, IL   \n",
       "7       Osteria la Spiga - Seattle, WA   \n",
       "4            I Ricchi - Washington, DC   \n",
       "8      Via dei Tribunali - Seattle, WA   \n",
       "9    Il Terrazzo Carmine - Seattle, WA   \n",
       "3              Otello - Washington, DC   \n",
       "6           Valentinos - Nashville, TN   \n",
       "0  Ristorante Piccolo - Washington, DC   \n",
       "2            Portofino - Arlington, VA   \n",
       "\n",
       "                                              Errors  # Errors  Score  \n",
       "5  [georgetown, rolle, tunnarella, ciliegina, imb...         5      5  \n",
       "1  [neri, orecchitte, spalla, agnelo, malloreddus...         6      4  \n",
       "7  [ragu, piadina, cestino, stuzzichini, ida, gno...         7      4  \n",
       "4  [romagnola, salsiccie, trota, buratta, paillar...        14      3  \n",
       "8  [cappuccino, caffe, espresso, puttanesca, dant...        11      3  \n",
       "9  [affogati, ortolano, spaghettini, asparaci, an...        15      3  \n",
       "3  [cappuccino, episelli, trota, espresso, mirell...        18      2  \n",
       "6  [arugula, parmesan, manhattan, scottish, espre...        18      2  \n",
       "0  [arugula, cioppino, altopiano, parigina, scarp...        26      1  \n",
       "2  [vinci, omaggi, veronese, picatta, cioppino, a...        24      1  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_errors.sort_values('Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Restaurant:  Il Canale - Washington, DC\n",
      "# Errors:  5\n",
      "Errors:  ['georgetown', 'rolle', 'tunnarella', 'ciliegina', 'imbottito']\n",
      "Score:  5\n",
      "------------------\n",
      "Restaurant:  La Storia - Chicago, IL\n",
      "# Errors:  6\n",
      "Errors:  ['neri', 'orecchitte', 'spalla', 'agnelo', 'malloreddus', 'sautee']\n",
      "Score:  4\n",
      "------------------\n",
      "Restaurant:  Osteria la Spiga - Seattle, WA\n",
      "# Errors:  7\n",
      "Errors:  ['ragu', 'piadina', 'cestino', 'stuzzichini', 'ida', 'gnocco', 'stridoli']\n",
      "Score:  4\n",
      "------------------\n",
      "Restaurant:  Via dei Tribunali - Seattle, WA\n",
      "# Errors:  11\n",
      "Errors:  ['cappuccino', 'caffe', 'espresso', 'puttanesca', 'dante', 'tribunali', 'campania', 'specialita', 'lupino', 'americano', 'spaccanapoli']\n",
      "Score:  3\n",
      "------------------\n",
      "Restaurant:  I Ricchi - Washington, DC\n",
      "# Errors:  14\n",
      "Errors:  ['romagnola', 'salsiccie', 'trota', 'buratta', 'paillar', 'costoletta', 'tortelloni', 'cavatelli', 'tagliarini', 'neri', 'bietola', 'allaglione', 'strascicate', 'vegetariano']\n",
      "Score:  3\n",
      "------------------\n",
      "Restaurant:  Il Terrazzo Carmine - Seattle, WA\n",
      "# Errors:  15\n",
      "Errors:  ['affogati', 'ortolano', 'spaghettini', 'asparaci', 'animelle', 'soffritti', 'capellini', 'ravioloni', 'piccata', 'campagnola', 'cioppino', 'provinciale', 'linquine', 'bue', 'capriolo']\n",
      "Score:  3\n",
      "------------------\n",
      "Restaurant:  Valentinos - Nashville, TN\n",
      "# Errors:  18\n",
      "Errors:  ['arugula', 'parmesan', 'manhattan', 'scottish', 'espresso', 'scarpariello', 'bucatini', 'gigli', 'flourless', 'flatbrea', 'osso', 'ribeye', 'wrapp', 'rubb', 'cioppino', 'oreganata', 'bucco', 'valentinos']\n",
      "Score:  2\n",
      "------------------\n",
      "Restaurant:  Otello - Washington, DC\n",
      "# Errors:  18\n",
      "Errors:  ['cappuccino', 'episelli', 'trota', 'espresso', 'mirella', 'puttanesca', 'sogliola', 'capellini', 'seafoo', 'tortellini', 'diavolo', 'piccata', 'burli', 'michele', 'scaloppini', 'rulata', 'alfredo', 'cuscinetti']\n",
      "Score:  2\n",
      "------------------\n",
      "Restaurant:  Portofino - Arlington, VA\n",
      "# Errors:  24\n",
      "Errors:  ['vinci', 'omaggi', 'veronese', 'picatta', 'cioppino', 'almondine', 'polpettini', 'linguini', 'bucatini', 'tortellini', 'nettuno', 'pizzaiola', 'spinacio', 'saltimboca', 'costoletta', 'triestina', 'italiano', 'fettucine', 'scalloppine', 'cesare', 'cacciuco', 'sant√©', 'alfredo', 'zuppe']\n",
      "Score:  1\n",
      "------------------\n",
      "Restaurant:  Ristorante Piccolo - Washington, DC\n",
      "# Errors:  26\n",
      "Errors:  ['arugula', 'cioppino', 'altopiano', 'parigina', 'scarpariello', 'bucatini', 'tortellini', 'italian', 'fradiavolo', 'paisano', 'oceano', 'manicotti', 'ragu', 'pistacche', 'veneto', 'italiano', 'salume', 'cesare', 'hoagie', 'puttanesca', 'capellini', 'piccata', 'murge', 'incrostato', 'spampinato', 'burger']\n",
      "Score:  1\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(dic_scoring.items(), key=lambda x:x[1]):\n",
    "    print(\"------------------\")\n",
    "    print(\"Restaurant: \", key)\n",
    "    print(\"# Errors: \", value[0][0])\n",
    "    print(\"Errors: \", value[0][1])\n",
    "    print('Score: ', value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
